{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### UniversitÃ  degli Studi di Milano, Data Science and Economics Master Degree\n",
    "\n",
    "# Backward propagation by Dynamic Programming\n",
    "\n",
    "### Alfio Ferrara\n",
    "\n",
    "Backward propagation can be used as a tool for finding the optimal policy by recirsively exploring the Agent options at different time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: the Taxation Game\n",
    "In this game, the player takes on the role of a politician with a **5-year mandate to govern their country**. The goal is to **maximize the total revenue** collected through taxation while balancing economic stability. Each year, the politician must decide between two levels of taxation:\n",
    "\n",
    "- **High Taxation**: Generates more revenue in the short term but risks lowering economic growth for future years.\n",
    "- **Moderate Taxation**: Generates less revenue in the short term but maintains economic growth for future years.\n",
    "\n",
    "At the end of the 5 years, the game evaluates the player's total revenue and their ability to sustain the economy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the game\n",
    "\n",
    "- action space: `(0, 1)` corresponding to _high taxes_ VS _moderate_taxes_\n",
    "- observation space: `(economy, years)`, where `economy` is the level of economy represented as _high growth_ or _low growth_; `years` is the number of years missing to the end of the politician mandate.\n",
    "- `reward`: \n",
    "\n",
    "| Economic Growth | High Taxation | Moderate Taxation |\n",
    "|------------------|--------------|-------------------|\n",
    "| High             | 15           | 10                |\n",
    "| Low              | 8            | 5                 |\n",
    "\n",
    "- `transition` (deterministic)\n",
    "\n",
    "| Economic Growth | High Taxation Impact | Moderate Taxation Impact |\n",
    "|------------------|----------------------|--------------------------|\n",
    "| High             | Decreases to Low    | Remains High             |\n",
    "| Low              | Remains Low         | Remains Low              |\n",
    "\n",
    "\n",
    "\n",
    "See the game implementation using gymnasium at [Taxation Game](./gymbase/environments.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "import gymbase.environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that, in terms of the Environment\n",
    "- 0: means `High`\n",
    "- 1: means `Low`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions\n",
      "[[1 0]\n",
      " [1 1]]\n",
      "Rewards\n",
      "[[15 10]\n",
      " [ 8  5]]\n"
     ]
    }
   ],
   "source": [
    "years = 3\n",
    "env = gym.make(\"TaxationGame-v0\", years=3, transitions=None, rewards=None)\n",
    "_, _ = env.reset()\n",
    "print(\"Transitions\")\n",
    "print(env.unwrapped.transitions)\n",
    "print(\"Rewards\")\n",
    "print(env.unwrapped.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Economic Growth: High, ðŸ“… Years Remaining: 3\n",
      "\tAction Taken: Moderate Taxation\n",
      "\tReward: 10, Next State: Low Economy\n",
      "\tTotal Reward: 10\n",
      "ðŸ“ˆ Economic Growth: High, ðŸ“… Years Remaining: 2\n",
      "\tAction Taken: Moderate Taxation\n",
      "\tReward: 10, Next State: Low Economy\n",
      "\tTotal Reward: 20\n",
      "ðŸ“ˆ Economic Growth: High, ðŸ“… Years Remaining: 1\n",
      "\tAction Taken: High Taxation\n",
      "\tReward: 15, Next State: Low Economy\n",
      "\tTotal Reward: 35\n",
      "ðŸ“ˆ Economic Growth: Low, ðŸ“… Years Remaining: 0\n",
      "Total Reward: 35\n"
     ]
    }
   ],
   "source": [
    "(economy, years), _ = env.reset()\n",
    "\n",
    "done, total_reward = False, 0\n",
    "\n",
    "env.render()\n",
    "\n",
    "i, actions = 0, [1, 1, 0]\n",
    "\n",
    "while not done:\n",
    "    #action = env.action_space.sample()\n",
    "    action = actions[i]\n",
    "    s_prime, reward, done, _, _ = env.step(action=action)\n",
    "    total_reward += reward\n",
    "    s_prime_label = 'High Economy' if s_prime == 0 else 'Low Economy'\n",
    "    print(f\"\\tAction Taken: {'High Taxation' if action == 0 else 'Moderate Taxation'}\")\n",
    "    print(f\"\\tReward: {reward}, Next State: {s_prime_label}\")\n",
    "    print(f\"\\tTotal Reward: {total_reward}\")\n",
    "    env.render()\n",
    "    i += 1\n",
    "print(f\"Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward induction\n",
    "\n",
    "As an example of recursive solution, we investigate **backward induction**. This means that we aim at finding the **optimal policy** by starting from the best solution at time $t = 0$ (the last year) and computing the alternatives for the previous years.\n",
    "\n",
    "In order to find the optimal policy $\\pi^{*}(s, t)$, where $s$ represents the current **economy** and $t$ the time when the decision has to be taken, we define the value of a state as $V(s, t)$.\n",
    "\n",
    "First, we take into account the **base**, that is the decision at time $t = 0$ (last year).\n",
    "At $t=0$ the game ends, which means that the optimal policy at that time will always be to enforce _high taxation_ (is the last year of the mandate, so who takes care of the future!).\n",
    "\n",
    "Moreover, the value of the state does not depend on the state itself, because at time $t$ you do not do any other action and do not get any reward, which means that:\n",
    "\n",
    "$$\n",
    "V(s, 0) = 0\\ \\forall s\n",
    "$$\n",
    "\n",
    "Then, for each state (_high economy_, _low economy_) and action (_high taxation_, _low_taxation_) we compute, recursively:\n",
    "\n",
    "$$\n",
    "Q(s, a, t) = r(s, a) + V(s', t - 1)\n",
    "$$\n",
    "\n",
    "Thus, as a first step, we need to update also $Q(s, a, 0) = r(s, a)$\n",
    "\n",
    "**Note** that, in general, $V(s, t) = \\max\\limits_{a} Q(s, a, t)$\n",
    "\n",
    "The final optimal policy is then\n",
    "\n",
    "$$\n",
    "\\pi^{*}(s, t) = \\arg\\max\\limits_{a} Q(s, a, t)\n",
    "$$\n",
    "\n",
    "![](./imgs/backward-induction.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_induction(environment: gym.Env):\n",
    "    # Transition table\n",
    "    transitions = environment.unwrapped.transitions\n",
    "    rewards = environment.unwrapped.rewards\n",
    "    states = environment.observation_space[0]\n",
    "    actions = environment.action_space\n",
    "\n",
    "    V = np.zeros((states.n, years + 1))\n",
    "    pi = np.zeros((states.n, years + 1))\n",
    "    Q = np.zeros((states.n, actions.n, years + 1))\n",
    "\n",
    "    for t in range(1, years + 1):\n",
    "        for state in range(states.n):\n",
    "            for a in range(environment.action_space.n):\n",
    "                s_prime = transitions[state, a]\n",
    "                r = rewards[state, a]\n",
    "                Q[state, a, t] = r + V[s_prime, t - 1] # Recursive step\n",
    "            # Update\n",
    "            V[state, t] = Q[state, :, t].max()\n",
    "            pi[state, t] = np.argmax(Q[state, :, t])\n",
    "    return pi, V, Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy\n",
      "[[0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]]\n",
      "Values\n",
      "[[ 0. 15. 25. 35.]\n",
      " [ 0.  8. 16. 24.]]\n"
     ]
    }
   ],
   "source": [
    "policy, V, Q = backward_induction(env)\n",
    "print(\"Policy\")\n",
    "print(policy)\n",
    "print(\"Values\")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23., 25.],\n",
       "       [16., 13.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that we can compute the optimal policy by backward induction because of the finite horizon and the deterministic transitions, which means that we do not need to explore the environment\n",
    "\n",
    "Let's check with different rewards, which makes High Taxation less competitive, like\n",
    "\n",
    "| Economic Growth | High Taxation | Moderate Taxation |\n",
    "|------------------|--------------|-------------------|\n",
    "| High             | 15           | 10                |\n",
    "| Low              | 1            | 5                 |\n",
    "\n",
    "Moreover, now if we do `Moderate Taxation` in `Low Economy` the economy turns `High`\n",
    "\n",
    "| Economic Growth | High Taxation Impact | Moderate Taxation Impact |\n",
    "|------------------|----------------------|--------------------------|\n",
    "| High             | Decreases to Low    | Remains High             |\n",
    "| Low              | Remains Low         | Increases to High              |\n",
    "\n",
    "![](./imgs/back-even.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([\n",
    "    [15, 10],\n",
    "    [1, 5]\n",
    "])\n",
    "transitions = np.array([\n",
    "    [1, 0],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "years = 3\n",
    "\n",
    "env = gym.make(\"TaxationGame-v0\", years=years, transitions=transitions, rewards=rewards)\n",
    "policy, V, Q = backward_induction(environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 1. 1. 1.]]\n",
      "Values\n",
      "[[ 0. 15. 25. 35.]\n",
      " [ 0.  5. 20. 30.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Policy\")\n",
    "print(policy)\n",
    "print(\"Values\")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
